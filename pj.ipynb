{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn import decomposition\n",
    "import pandas as pd\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "from keras.optimizers import Adadelta, SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import *\n",
    "from collections import Counter \n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "np.random.seed(42)\n",
    "\n",
    "%matplotlib inline\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (12, 12)      # setting default size of plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 预处理：司机-类别-图片名字\n",
    "driver_char = ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022',\n",
    "                  'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045',\n",
    "                  'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061',\n",
    "                  'p064', 'p066', 'p072', 'p075', 'p081']\n",
    "driver_data = pd.read_csv('driver_imgs_list.csv')\n",
    "driver = driver_data['subject']\n",
    "driver_class = driver_data['classname']\n",
    "driver_img = driver_data['img']\n",
    "driver_dict = dict()\n",
    "for i in range(len(driver)):\n",
    "    if driver[i] not in driver_dict.keys():\n",
    "        driver_dict[driver[i]] = dict()\n",
    "    if driver_class[i] not in driver_dict[driver[i]].keys():\n",
    "        driver_dict[driver[i]][driver_class[i]] = []\n",
    "    driver_dict[driver[i]][driver_class[i]].append(driver_img[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# ResNet的图片减均值处理\n",
    "def preprocess_input(x):\n",
    "    # Already 'BGR' in openCV\n",
    "    # Zero-center by mean pixel\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 将模型训练得到的bottleneck features保存到本地，方便迁移学习使用，可以节约计算时间\n",
    "def save_bottlebeck_features(X_train, y_train, X_valid, y_valid, idx = None):\n",
    "    batch_size = 1\n",
    "    nb_train_samples = X_train.shape[0]\n",
    "    nb_valid_samples = X_valid.shape[0]\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "    valid_datagen = ImageDataGenerator( preprocessing_function = preprocess_input)\n",
    "\n",
    "    ResNet50_model = ResNet50(include_top=False, weights='imagenet', pooling='max')\n",
    "\n",
    "    generator = train_datagen.flow(\n",
    "        X_train,y_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    " \n",
    "    bottleneck_features_train = ResNet50_model.predict_generator(\n",
    "                                generator,  nb_train_samples)\n",
    "    if idx is None:\n",
    "        np.save(open('ResNet50_bottleneck_features_train.npy', 'w'),\n",
    "                bottleneck_features_train)\n",
    "        np.save(open('ResNet50_bottleneck_y_train.npy', 'w'), y_train)\n",
    "    else:\n",
    "        np.save(open('ResNet50_bottleneck_features_train_'+str(idx)+'.npy', 'w'),\n",
    "                bottleneck_features_train)\n",
    "        np.save(open('ResNet50_bottleneck_y_train_'+str(idx)+'.npy', 'w'), y_train)\n",
    "    \n",
    "\n",
    "    generator = valid_datagen.flow(\n",
    "        X_valid, y_valid,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "  \n",
    "    bottleneck_features_validation = ResNet50_model.predict_generator(\n",
    "                                     generator, nb_valid_samples)\n",
    "    if idx is None:\n",
    "        np.save(open('ResNet50_bottleneck_features_validation.npy', 'w'),\n",
    "                bottleneck_features_validation)\n",
    "        np.save(open('ResNet50_bottleneck_y_valid.npy', 'w'), y_valid)\n",
    "    else:\n",
    "        np.save(open('ResNet50_bottleneck_features_validation_'+str(idx)+'.npy', 'w'),\n",
    "                bottleneck_features_validation)\n",
    "        np.save(open('ResNet50_bottleneck_y_valid_'+str(idx)+'.npy', 'w'), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 按照司机编号分割训练数据和验证数据。\n",
    "def train_valid_split( resize, train_drivers, valid_drivers):\n",
    "    \n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_valid = []\n",
    "    y_valid = []\n",
    "    \n",
    "    print \"Train drivers: \"+str(train_drivers)\n",
    "    print \"Validation drivers: \"+str(valid_drivers)\n",
    "\n",
    "    for j in range(10):\n",
    "        path = os.path.join('.', 'imgs', 'train', 'c'+str(j), '*.jpg')\n",
    "        files = glob.glob(path)\n",
    "        for f in files:\n",
    "            bname = os.path.basename(f)\n",
    "            img = cv2.imread(f)\n",
    "            img = cv2.resize(img, resize)\n",
    "            # train validation split\n",
    "            valid_driver_imgs = [driver_dict[d]['c'+str(j)] for d in valid_drivers]\n",
    "            valid_driver_imgs = np.concatenate(valid_driver_imgs, axis=0)\n",
    "            train_driver_imgs = [driver_dict[d]['c'+str(j)] for d in train_drivers]\n",
    "            train_driver_imgs = np.concatenate(train_driver_imgs, axis=0)\n",
    "            if bname in valid_driver_imgs:\n",
    "                X_valid.append(img)\n",
    "                y_valid.append(j)\n",
    "            elif bname in train_driver_imgs:\n",
    "                X_train.append(img)\n",
    "                y_train.append(j)\n",
    "    X_train = np.array(X_train, dtype=np.uint8)\n",
    "    y_train = np.array(y_train, dtype=np.uint8)\n",
    "    y_train = to_categorical(y_train)\n",
    "    X_valid = np.array(X_valid, dtype=np.uint8)\n",
    "    y_valid = np.array(y_valid, dtype=np.uint8)  \n",
    "    y_valid = to_categorical(y_valid)\n",
    "\n",
    "    print \"Train data shape:\"+str(X_train.shape)\n",
    "    print \"Train label shape:\"+str(y_train.shape)\n",
    "    print  \"Validation data shape:\"+str(X_valid.shape)\n",
    "    print  \"Validation label shape:\"+str(y_valid.shape)\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1 round\n",
      "Train drivers: ['p026', 'p050', 'p002', 'p075', 'p041', 'p035', 'p045', 'p012', 'p072', 'p021', 'p014', 'p042', 'p049', 'p015', 'p016', 'p064', 'p051', 'p066', 'p052', 'p081', 'p061', 'p024', 'p039', 'p047', 'p056']\n",
      "Validation drivers: ['p022']\n",
      "Train data shape:(21191, 224, 224, 3)\n",
      "Train label shape:(21191, 10)\n",
      "Validation data shape:(1233, 224, 224, 3)\n",
      "Validation label shape:(1233, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21191, 2048)\n",
      "Train label shape:(21191, 10)\n",
      "Valid data shape: (1233, 2048)\n",
      "Valid label shape:(1233, 10)\n",
      "Train on 21191 samples, validate on 1233 samples\n",
      "Epoch 1/30\n",
      "21191/21191 [==============================] - 6s - loss: 3.2589 - acc: 0.1957 - val_loss: 1.4513 - val_acc: 0.5985\n",
      "Epoch 2/30\n",
      "21191/21191 [==============================] - 1s - loss: 1.9004 - acc: 0.3820 - val_loss: 1.2276 - val_acc: 0.6472\n",
      "Epoch 3/30\n",
      "21191/21191 [==============================] - 1s - loss: 1.4491 - acc: 0.5056 - val_loss: 1.0369 - val_acc: 0.7583\n",
      "Epoch 4/30\n",
      "21191/21191 [==============================] - 1s - loss: 1.2425 - acc: 0.5722 - val_loss: 1.0336 - val_acc: 0.6967\n",
      "Epoch 5/30\n",
      "21191/21191 [==============================] - 1s - loss: 1.1365 - acc: 0.6118 - val_loss: 0.9366 - val_acc: 0.7802\n",
      "Epoch 6/30\n",
      "21191/21191 [==============================] - 1s - loss: 1.0540 - acc: 0.6389 - val_loss: 0.8910 - val_acc: 0.7664\n",
      "Epoch 7/30\n",
      "21191/21191 [==============================] - 1s - loss: 1.0231 - acc: 0.6519 - val_loss: 0.9442 - val_acc: 0.7445\n",
      "Epoch 8/30\n",
      "21191/21191 [==============================] - 1s - loss: 1.0027 - acc: 0.6618 - val_loss: 0.9371 - val_acc: 0.7364\n",
      "Epoch 9/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9744 - acc: 0.6689 - val_loss: 0.9067 - val_acc: 0.6910\n",
      "Epoch 10/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9569 - acc: 0.6758 - val_loss: 0.9397 - val_acc: 0.6878\n",
      "Epoch 11/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9430 - acc: 0.6788 - val_loss: 0.8207 - val_acc: 0.7794\n",
      "Epoch 12/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9342 - acc: 0.6822 - val_loss: 0.8225 - val_acc: 0.7908\n",
      "Epoch 13/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9307 - acc: 0.6834 - val_loss: 0.8363 - val_acc: 0.7616\n",
      "Epoch 14/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9241 - acc: 0.6875 - val_loss: 0.7921 - val_acc: 0.7762\n",
      "Epoch 15/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9075 - acc: 0.6908 - val_loss: 0.8204 - val_acc: 0.7689\n",
      "Epoch 16/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9143 - acc: 0.6921 - val_loss: 0.7842 - val_acc: 0.7948\n",
      "Epoch 17/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.9062 - acc: 0.6923 - val_loss: 0.8176 - val_acc: 0.7543\n",
      "Epoch 18/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8969 - acc: 0.6921 - val_loss: 0.8357 - val_acc: 0.7745\n",
      "Epoch 19/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8925 - acc: 0.6994 - val_loss: 0.7708 - val_acc: 0.7810\n",
      "Epoch 20/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8933 - acc: 0.6966 - val_loss: 0.8304 - val_acc: 0.7470\n",
      "Epoch 21/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8932 - acc: 0.6943 - val_loss: 0.8052 - val_acc: 0.7745\n",
      "Epoch 22/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8954 - acc: 0.6952 - val_loss: 0.8300 - val_acc: 0.7648\n",
      "Epoch 23/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8832 - acc: 0.7042 - val_loss: 0.7947 - val_acc: 0.7599\n",
      "Epoch 24/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8804 - acc: 0.6987 - val_loss: 0.7730 - val_acc: 0.7705\n",
      "Epoch 25/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8696 - acc: 0.7047 - val_loss: 0.7602 - val_acc: 0.7745\n",
      "Epoch 26/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8595 - acc: 0.7070 - val_loss: 0.8200 - val_acc: 0.7340\n",
      "Epoch 27/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8754 - acc: 0.7023 - val_loss: 0.7874 - val_acc: 0.7680\n",
      "Epoch 28/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8799 - acc: 0.7026 - val_loss: 0.8236 - val_acc: 0.7307\n",
      "Epoch 29/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8640 - acc: 0.7051 - val_loss: 0.7962 - val_acc: 0.7518\n",
      "Epoch 30/30\n",
      "21191/21191 [==============================] - 1s - loss: 0.8711 - acc: 0.7004 - val_loss: 0.7858 - val_acc: 0.7762\n",
      "In 2 round\n",
      "Train drivers: ['p021', 'p026', 'p024', 'p061', 'p075', 'p039', 'p052', 'p012', 'p045', 'p042', 'p035', 'p056', 'p002', 'p051', 'p064', 'p041', 'p072', 'p047', 'p014', 'p081', 'p015', 'p049', 'p016', 'p050', 'p022']\n",
      "Validation drivers: ['p066']\n",
      "Train data shape:(21390, 224, 224, 3)\n",
      "Train label shape:(21390, 10)\n",
      "Validation data shape:(1034, 224, 224, 3)\n",
      "Validation label shape:(1034, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21390, 2048)\n",
      "Train label shape:(21390, 10)\n",
      "Valid data shape: (1034, 2048)\n",
      "Valid label shape:(1034, 10)\n",
      "Train on 21390 samples, validate on 1034 samples\n",
      "Epoch 1/30\n",
      "21390/21390 [==============================] - 1s - loss: 3.3220 - acc: 0.1922 - val_loss: 1.4900 - val_acc: 0.5348\n",
      "Epoch 2/30\n",
      "21390/21390 [==============================] - 1s - loss: 1.9159 - acc: 0.3835 - val_loss: 1.2867 - val_acc: 0.6112\n",
      "Epoch 3/30\n",
      "21390/21390 [==============================] - 1s - loss: 1.4399 - acc: 0.5063 - val_loss: 1.1785 - val_acc: 0.6228\n",
      "Epoch 4/30\n",
      "21390/21390 [==============================] - 1s - loss: 1.2348 - acc: 0.5760 - val_loss: 1.0716 - val_acc: 0.7041\n",
      "Epoch 5/30\n",
      "21390/21390 [==============================] - 1s - loss: 1.1233 - acc: 0.6152 - val_loss: 1.0731 - val_acc: 0.6857\n",
      "Epoch 6/30\n",
      "21390/21390 [==============================] - 1s - loss: 1.0567 - acc: 0.6392 - val_loss: 1.0747 - val_acc: 0.6605\n",
      "Epoch 7/30\n",
      "21390/21390 [==============================] - 1s - loss: 1.0141 - acc: 0.6558 - val_loss: 1.0753 - val_acc: 0.6489\n",
      "Epoch 8/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9908 - acc: 0.6657 - val_loss: 1.0489 - val_acc: 0.6702\n",
      "Epoch 9/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9554 - acc: 0.6772 - val_loss: 1.0313 - val_acc: 0.6857\n",
      "Epoch 10/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9387 - acc: 0.6823 - val_loss: 1.0272 - val_acc: 0.6702\n",
      "Epoch 11/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9386 - acc: 0.6775 - val_loss: 1.0245 - val_acc: 0.6528\n",
      "Epoch 12/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9172 - acc: 0.6893 - val_loss: 1.0544 - val_acc: 0.6654\n",
      "Epoch 13/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9104 - acc: 0.6929 - val_loss: 1.0073 - val_acc: 0.6702\n",
      "Epoch 14/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9080 - acc: 0.6930 - val_loss: 1.0323 - val_acc: 0.6422\n",
      "Epoch 15/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.8994 - acc: 0.6943 - val_loss: 0.9869 - val_acc: 0.6809\n",
      "Epoch 16/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.9023 - acc: 0.6960 - val_loss: 1.0360 - val_acc: 0.6799\n",
      "Epoch 17/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.8881 - acc: 0.6973 - val_loss: 1.0401 - val_acc: 0.6731\n",
      "Epoch 18/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.8836 - acc: 0.6992 - val_loss: 1.0594 - val_acc: 0.6547\n",
      "Epoch 19/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.8874 - acc: 0.6969 - val_loss: 1.0588 - val_acc: 0.6393\n",
      "Epoch 20/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.8796 - acc: 0.7038 - val_loss: 1.0175 - val_acc: 0.6499\n",
      "Epoch 21/30\n",
      "21390/21390 [==============================] - 1s - loss: 0.8810 - acc: 0.6977 - val_loss: 0.9973 - val_acc: 0.6750\n",
      "In 3 round\n",
      "Train drivers: ['p066', 'p035', 'p047', 'p016', 'p015', 'p014', 'p026', 'p051', 'p042', 'p039', 'p012', 'p072', 'p002', 'p045', 'p061', 'p052', 'p064', 'p049', 'p021', 'p050', 'p075', 'p041', 'p081', 'p024', 'p056']\n",
      "Validation drivers: ['p022']\n",
      "Train data shape:(21191, 224, 224, 3)\n",
      "Train label shape:(21191, 10)\n",
      "Validation data shape:(1233, 224, 224, 3)\n",
      "Validation label shape:(1233, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21198, 2048)\n",
      "Train label shape:(21198, 10)\n",
      "Valid data shape: (1226, 2048)\n",
      "Valid label shape:(1226, 10)\n",
      "Train on 21198 samples, validate on 1226 samples\n",
      "Epoch 1/30\n",
      "21198/21198 [==============================] - 1s - loss: 3.3631 - acc: 0.1916 - val_loss: 1.5525 - val_acc: 0.5962\n",
      "Epoch 2/30\n",
      "21198/21198 [==============================] - 1s - loss: 1.9306 - acc: 0.3724 - val_loss: 1.3181 - val_acc: 0.6126\n",
      "Epoch 3/30\n",
      "21198/21198 [==============================] - 1s - loss: 1.4549 - acc: 0.5058 - val_loss: 1.2640 - val_acc: 0.5791\n",
      "Epoch 4/30\n",
      "21198/21198 [==============================] - 1s - loss: 1.2416 - acc: 0.5736 - val_loss: 1.1242 - val_acc: 0.6591\n",
      "Epoch 5/30\n",
      "21198/21198 [==============================] - 1s - loss: 1.1496 - acc: 0.6073 - val_loss: 1.1157 - val_acc: 0.6574\n",
      "Epoch 6/30\n",
      "21198/21198 [==============================] - 1s - loss: 1.0739 - acc: 0.6358 - val_loss: 1.1430 - val_acc: 0.6207\n",
      "Epoch 7/30\n",
      "21198/21198 [==============================] - 1s - loss: 1.0218 - acc: 0.6517 - val_loss: 1.0552 - val_acc: 0.6558\n",
      "Epoch 8/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9967 - acc: 0.6637 - val_loss: 1.0099 - val_acc: 0.6998\n",
      "Epoch 9/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9757 - acc: 0.6652 - val_loss: 1.0021 - val_acc: 0.7015\n",
      "Epoch 10/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9652 - acc: 0.6713 - val_loss: 1.0372 - val_acc: 0.6378\n",
      "Epoch 11/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9497 - acc: 0.6736 - val_loss: 0.9619 - val_acc: 0.7088\n",
      "Epoch 12/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9354 - acc: 0.6822 - val_loss: 1.0376 - val_acc: 0.6558\n",
      "Epoch 13/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9241 - acc: 0.6847 - val_loss: 1.0682 - val_acc: 0.6207\n",
      "Epoch 14/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9321 - acc: 0.6827 - val_loss: 0.9842 - val_acc: 0.6558\n",
      "Epoch 15/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9094 - acc: 0.6913 - val_loss: 0.9867 - val_acc: 0.6794\n",
      "Epoch 16/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9037 - acc: 0.6947 - val_loss: 0.9861 - val_acc: 0.6697\n",
      "Epoch 17/30\n",
      "21198/21198 [==============================] - 1s - loss: 0.9050 - acc: 0.6920 - val_loss: 1.0777 - val_acc: 0.5873\n",
      "In 4 round\n",
      "Train drivers: ['p056', 'p041', 'p035', 'p026', 'p022', 'p072', 'p052', 'p051', 'p064', 'p047', 'p015', 'p045', 'p016', 'p042', 'p061', 'p039', 'p014', 'p050', 'p075', 'p081', 'p002', 'p049', 'p024', 'p066', 'p012']\n",
      "Validation drivers: ['p021']\n",
      "Train data shape:(21187, 224, 224, 3)\n",
      "Train label shape:(21187, 10)\n",
      "Validation data shape:(1237, 224, 224, 3)\n",
      "Validation label shape:(1237, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21630, 2048)\n",
      "Train label shape:(21630, 10)\n",
      "Valid data shape: (794, 2048)\n",
      "Valid label shape:(794, 10)\n",
      "Train on 21630 samples, validate on 794 samples\n",
      "Epoch 1/30\n",
      "21630/21630 [==============================] - 1s - loss: 3.3033 - acc: 0.1939 - val_loss: 1.4291 - val_acc: 0.5705\n",
      "Epoch 2/30\n",
      "21630/21630 [==============================] - 1s - loss: 1.8997 - acc: 0.3864 - val_loss: 1.1615 - val_acc: 0.6322\n",
      "Epoch 3/30\n",
      "21630/21630 [==============================] - 1s - loss: 1.4382 - acc: 0.5074 - val_loss: 1.0735 - val_acc: 0.6877\n",
      "Epoch 4/30\n",
      "21630/21630 [==============================] - 1s - loss: 1.2375 - acc: 0.5783 - val_loss: 0.9737 - val_acc: 0.7204\n",
      "Epoch 5/30\n",
      "21630/21630 [==============================] - 1s - loss: 1.1200 - acc: 0.6145 - val_loss: 0.9570 - val_acc: 0.7166\n",
      "Epoch 6/30\n",
      "21630/21630 [==============================] - 1s - loss: 1.0694 - acc: 0.6346 - val_loss: 0.8759 - val_acc: 0.7632\n",
      "Epoch 7/30\n",
      "21630/21630 [==============================] - 1s - loss: 1.0364 - acc: 0.6471 - val_loss: 0.8719 - val_acc: 0.7443\n",
      "Epoch 8/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9947 - acc: 0.6626 - val_loss: 0.8504 - val_acc: 0.7443\n",
      "Epoch 9/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9752 - acc: 0.6693 - val_loss: 0.8349 - val_acc: 0.7531\n",
      "Epoch 10/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9686 - acc: 0.6732 - val_loss: 0.8304 - val_acc: 0.7720\n",
      "Epoch 11/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9426 - acc: 0.6785 - val_loss: 0.8116 - val_acc: 0.7657\n",
      "Epoch 12/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9312 - acc: 0.6848 - val_loss: 0.8103 - val_acc: 0.7481\n",
      "Epoch 13/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9200 - acc: 0.6876 - val_loss: 0.7930 - val_acc: 0.7859\n",
      "Epoch 14/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9204 - acc: 0.6871 - val_loss: 0.7919 - val_acc: 0.7695\n",
      "Epoch 15/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9095 - acc: 0.6948 - val_loss: 0.8146 - val_acc: 0.7582\n",
      "Epoch 16/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9023 - acc: 0.6937 - val_loss: 0.7609 - val_acc: 0.7884\n",
      "Epoch 17/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.9036 - acc: 0.6914 - val_loss: 0.7816 - val_acc: 0.7771\n",
      "Epoch 18/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8982 - acc: 0.6937 - val_loss: 0.7753 - val_acc: 0.7708\n",
      "Epoch 19/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8967 - acc: 0.6967 - val_loss: 0.7761 - val_acc: 0.7582\n",
      "Epoch 20/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8911 - acc: 0.6993 - val_loss: 0.7565 - val_acc: 0.7733\n",
      "Epoch 21/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8917 - acc: 0.6989 - val_loss: 0.7278 - val_acc: 0.7935\n",
      "Epoch 22/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8889 - acc: 0.7006 - val_loss: 0.7723 - val_acc: 0.7695\n",
      "Epoch 23/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8738 - acc: 0.7075 - val_loss: 0.7493 - val_acc: 0.7695\n",
      "Epoch 24/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8793 - acc: 0.6978 - val_loss: 0.7522 - val_acc: 0.7947\n",
      "Epoch 25/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8798 - acc: 0.6991 - val_loss: 0.7582 - val_acc: 0.7758\n",
      "Epoch 26/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8858 - acc: 0.6996 - val_loss: 0.7292 - val_acc: 0.7985\n",
      "Epoch 27/30\n",
      "21630/21630 [==============================] - 1s - loss: 0.8674 - acc: 0.7065 - val_loss: 0.7560 - val_acc: 0.7695\n",
      "In 5 round\n",
      "Train drivers: ['p012', 'p051', 'p002', 'p021', 'p081', 'p022', 'p056', 'p050', 'p075', 'p024', 'p072', 'p064', 'p066', 'p061', 'p047', 'p035', 'p041', 'p014', 'p042', 'p016', 'p052', 'p015', 'p045', 'p026', 'p049']\n",
      "Validation drivers: ['p039']\n",
      "Train data shape:(21773, 224, 224, 3)\n",
      "Train label shape:(21773, 10)\n",
      "Validation data shape:(651, 224, 224, 3)\n",
      "Validation label shape:(651, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21700, 2048)\n",
      "Train label shape:(21700, 10)\n",
      "Valid data shape: (724, 2048)\n",
      "Valid label shape:(724, 10)\n",
      "Train on 21700 samples, validate on 724 samples\n",
      "Epoch 1/30\n",
      "21700/21700 [==============================] - 1s - loss: 3.3985 - acc: 0.1826 - val_loss: 1.3352 - val_acc: 0.5994\n",
      "Epoch 2/30\n",
      "21700/21700 [==============================] - 1s - loss: 1.9577 - acc: 0.3655 - val_loss: 1.0736 - val_acc: 0.6575\n",
      "Epoch 3/30\n",
      "21700/21700 [==============================] - 1s - loss: 1.4672 - acc: 0.4963 - val_loss: 0.8702 - val_acc: 0.7818\n",
      "Epoch 4/30\n",
      "21700/21700 [==============================] - 1s - loss: 1.2615 - acc: 0.5656 - val_loss: 0.8278 - val_acc: 0.7776\n",
      "Epoch 5/30\n",
      "21700/21700 [==============================] - 1s - loss: 1.1429 - acc: 0.6040 - val_loss: 0.9545 - val_acc: 0.6367\n",
      "Epoch 6/30\n",
      "21700/21700 [==============================] - 1s - loss: 1.0850 - acc: 0.6270 - val_loss: 0.8871 - val_acc: 0.6699\n",
      "Epoch 7/30\n",
      "21700/21700 [==============================] - 1s - loss: 1.0420 - acc: 0.6454 - val_loss: 0.7209 - val_acc: 0.8011\n",
      "Epoch 8/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9991 - acc: 0.6571 - val_loss: 0.7885 - val_acc: 0.7583\n",
      "Epoch 9/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9719 - acc: 0.6691 - val_loss: 0.8389 - val_acc: 0.7417\n",
      "Epoch 10/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9628 - acc: 0.6731 - val_loss: 0.7191 - val_acc: 0.8218\n",
      "Epoch 11/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9561 - acc: 0.6752 - val_loss: 0.6711 - val_acc: 0.8384\n",
      "Epoch 12/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9386 - acc: 0.6829 - val_loss: 0.8180 - val_acc: 0.7320\n",
      "Epoch 13/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9280 - acc: 0.6821 - val_loss: 0.7571 - val_acc: 0.7680\n",
      "Epoch 14/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9283 - acc: 0.6837 - val_loss: 0.7276 - val_acc: 0.7831\n",
      "Epoch 15/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9235 - acc: 0.6827 - val_loss: 0.7039 - val_acc: 0.7914\n",
      "Epoch 16/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9146 - acc: 0.6839 - val_loss: 0.6916 - val_acc: 0.7831\n",
      "Epoch 17/30\n",
      "21700/21700 [==============================] - 1s - loss: 0.9154 - acc: 0.6887 - val_loss: 0.6906 - val_acc: 0.7831\n",
      "In 6 round\n",
      "Train drivers: ['p072', 'p042', 'p024', 'p064', 'p081', 'p041', 'p047', 'p039', 'p022', 'p026', 'p014', 'p061', 'p035', 'p015', 'p075', 'p052', 'p051', 'p021', 'p056', 'p049', 'p016', 'p002', 'p066', 'p050', 'p045']\n",
      "Validation drivers: ['p012']\n",
      "Train data shape:(21601, 224, 224, 3)\n",
      "Train label shape:(21601, 10)\n",
      "Validation data shape:(823, 224, 224, 3)\n",
      "Validation label shape:(823, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21615, 2048)\n",
      "Train label shape:(21615, 10)\n",
      "Valid data shape: (809, 2048)\n",
      "Valid label shape:(809, 10)\n",
      "Train on 21615 samples, validate on 809 samples\n",
      "Epoch 1/30\n",
      "21615/21615 [==============================] - 1s - loss: 3.2537 - acc: 0.1991 - val_loss: 1.5825 - val_acc: 0.5303\n",
      "Epoch 2/30\n",
      "21615/21615 [==============================] - 1s - loss: 1.8559 - acc: 0.3944 - val_loss: 1.3651 - val_acc: 0.5587\n",
      "Epoch 3/30\n",
      "21615/21615 [==============================] - 1s - loss: 1.4196 - acc: 0.5133 - val_loss: 1.2692 - val_acc: 0.5921\n",
      "Epoch 4/30\n",
      "21615/21615 [==============================] - 1s - loss: 1.2403 - acc: 0.5757 - val_loss: 1.1400 - val_acc: 0.6452\n",
      "Epoch 5/30\n",
      "21615/21615 [==============================] - 1s - loss: 1.1166 - acc: 0.6204 - val_loss: 1.1554 - val_acc: 0.6168\n",
      "Epoch 6/30\n",
      "21615/21615 [==============================] - 1s - loss: 1.0601 - acc: 0.6394 - val_loss: 1.0801 - val_acc: 0.6823\n",
      "Epoch 7/30\n",
      "21615/21615 [==============================] - 1s - loss: 1.0180 - acc: 0.6524 - val_loss: 1.0225 - val_acc: 0.6823\n",
      "Epoch 8/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9893 - acc: 0.6615 - val_loss: 0.9600 - val_acc: 0.7219\n",
      "Epoch 9/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9687 - acc: 0.6686 - val_loss: 0.9391 - val_acc: 0.7268\n",
      "Epoch 10/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9488 - acc: 0.6757 - val_loss: 0.9499 - val_acc: 0.7268\n",
      "Epoch 11/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9380 - acc: 0.6833 - val_loss: 0.9706 - val_acc: 0.6873\n",
      "Epoch 12/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9278 - acc: 0.6845 - val_loss: 0.9257 - val_acc: 0.7169\n",
      "Epoch 13/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9142 - acc: 0.6898 - val_loss: 0.9440 - val_acc: 0.7182\n",
      "Epoch 14/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9187 - acc: 0.6872 - val_loss: 0.9897 - val_acc: 0.6786\n",
      "Epoch 15/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.9098 - acc: 0.6926 - val_loss: 0.9125 - val_acc: 0.7244\n",
      "Epoch 16/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8997 - acc: 0.6931 - val_loss: 0.9339 - val_acc: 0.6996\n",
      "Epoch 17/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8974 - acc: 0.6943 - val_loss: 0.9446 - val_acc: 0.7046\n",
      "Epoch 18/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8879 - acc: 0.6993 - val_loss: 0.8985 - val_acc: 0.7293\n",
      "Epoch 19/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8887 - acc: 0.6977 - val_loss: 0.8783 - val_acc: 0.7281\n",
      "Epoch 20/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8797 - acc: 0.7009 - val_loss: 0.8898 - val_acc: 0.7268\n",
      "Epoch 21/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8796 - acc: 0.7020 - val_loss: 0.8870 - val_acc: 0.7367\n",
      "Epoch 22/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8814 - acc: 0.7007 - val_loss: 0.9000 - val_acc: 0.7169\n",
      "Epoch 23/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8729 - acc: 0.7040 - val_loss: 0.8888 - val_acc: 0.7293\n",
      "Epoch 24/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8798 - acc: 0.7017 - val_loss: 0.8595 - val_acc: 0.7367\n",
      "Epoch 25/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8734 - acc: 0.7028 - val_loss: 0.8912 - val_acc: 0.7379\n",
      "Epoch 26/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8809 - acc: 0.7028 - val_loss: 0.8911 - val_acc: 0.7330\n",
      "Epoch 27/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8696 - acc: 0.7037 - val_loss: 0.8824 - val_acc: 0.7392\n",
      "Epoch 28/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8822 - acc: 0.6988 - val_loss: 0.8681 - val_acc: 0.7441\n",
      "Epoch 29/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8624 - acc: 0.7060 - val_loss: 0.8791 - val_acc: 0.7404\n",
      "Epoch 30/30\n",
      "21615/21615 [==============================] - 1s - loss: 0.8628 - acc: 0.7047 - val_loss: 0.8772 - val_acc: 0.7305\n",
      "In 7 round\n",
      "Train drivers: ['p022', 'p051', 'p024', 'p021', 'p041', 'p064', 'p075', 'p014', 'p035', 'p015', 'p012', 'p049', 'p052', 'p026', 'p066', 'p039', 'p056', 'p050', 'p016', 'p045', 'p072', 'p081', 'p061', 'p002', 'p047']\n",
      "Validation drivers: ['p042']\n",
      "Train data shape:(21833, 224, 224, 3)\n",
      "Train label shape:(21833, 10)\n",
      "Validation data shape:(591, 224, 224, 3)\n",
      "Validation label shape:(591, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21576, 2048)\n",
      "Train label shape:(21576, 10)\n",
      "Valid data shape: (848, 2048)\n",
      "Valid label shape:(848, 10)\n",
      "Train on 21576 samples, validate on 848 samples\n",
      "Epoch 1/30\n",
      "21576/21576 [==============================] - 1s - loss: 3.3436 - acc: 0.1864 - val_loss: 1.3378 - val_acc: 0.5613\n",
      "Epoch 2/30\n",
      "21576/21576 [==============================] - 1s - loss: 1.9122 - acc: 0.3778 - val_loss: 1.0803 - val_acc: 0.6899\n",
      "Epoch 3/30\n",
      "21576/21576 [==============================] - 1s - loss: 1.4513 - acc: 0.5049 - val_loss: 1.0831 - val_acc: 0.5991\n",
      "Epoch 4/30\n",
      "21576/21576 [==============================] - 1s - loss: 1.2456 - acc: 0.5695 - val_loss: 0.9502 - val_acc: 0.6368\n",
      "Epoch 5/30\n",
      "21576/21576 [==============================] - 1s - loss: 1.1345 - acc: 0.6123 - val_loss: 0.8923 - val_acc: 0.7075\n",
      "Epoch 6/30\n",
      "21576/21576 [==============================] - 1s - loss: 1.0658 - acc: 0.6375 - val_loss: 0.8962 - val_acc: 0.6474\n",
      "Epoch 7/30\n",
      "21576/21576 [==============================] - 1s - loss: 1.0285 - acc: 0.6486 - val_loss: 0.8703 - val_acc: 0.7158\n",
      "Epoch 8/30\n",
      "21576/21576 [==============================] - 1s - loss: 1.0055 - acc: 0.6587 - val_loss: 0.8723 - val_acc: 0.6899\n",
      "Epoch 9/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9817 - acc: 0.6662 - val_loss: 0.8314 - val_acc: 0.6781\n",
      "Epoch 10/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9639 - acc: 0.6739 - val_loss: 0.7980 - val_acc: 0.7417\n",
      "Epoch 11/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9513 - acc: 0.6754 - val_loss: 0.7942 - val_acc: 0.7547\n",
      "Epoch 12/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9294 - acc: 0.6852 - val_loss: 0.7879 - val_acc: 0.7358\n",
      "Epoch 13/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9258 - acc: 0.6884 - val_loss: 0.8158 - val_acc: 0.6993\n",
      "Epoch 14/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9224 - acc: 0.6858 - val_loss: 0.7723 - val_acc: 0.7724\n",
      "Epoch 15/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9149 - acc: 0.6921 - val_loss: 0.7811 - val_acc: 0.7146\n",
      "Epoch 16/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9212 - acc: 0.6861 - val_loss: 0.7972 - val_acc: 0.7441\n",
      "Epoch 17/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9138 - acc: 0.6908 - val_loss: 0.7471 - val_acc: 0.7300\n",
      "Epoch 18/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9015 - acc: 0.6926 - val_loss: 0.8185 - val_acc: 0.7288\n",
      "Epoch 19/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.9046 - acc: 0.6935 - val_loss: 0.7629 - val_acc: 0.7052\n",
      "Epoch 20/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.8875 - acc: 0.6980 - val_loss: 0.7849 - val_acc: 0.6946\n",
      "Epoch 21/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.8928 - acc: 0.6958 - val_loss: 0.7472 - val_acc: 0.7736\n",
      "Epoch 22/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.8934 - acc: 0.6968 - val_loss: 0.7695 - val_acc: 0.7535\n",
      "Epoch 23/30\n",
      "21576/21576 [==============================] - 1s - loss: 0.8917 - acc: 0.6990 - val_loss: 0.7735 - val_acc: 0.7382\n",
      "In 8 round\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p042', 'p024', 'p039', 'p066', 'p041', 'p072', 'p061', 'p012', 'p049', 'p064', 'p021', 'p056', 'p045', 'p052', 'p050', 'p081', 'p022', 'p026', 'p014', 'p035', 'p051', 'p047']\n",
      "Validation drivers: ['p002']\n",
      "Train data shape:(21699, 224, 224, 3)\n",
      "Train label shape:(21699, 10)\n",
      "Validation data shape:(725, 224, 224, 3)\n",
      "Validation label shape:(725, 10)\n",
      "Train fully connected layers...\n",
      "Train data shape: (21228, 2048)\n",
      "Train label shape:(21228, 10)\n",
      "Valid data shape: (1196, 2048)\n",
      "Valid label shape:(1196, 10)\n",
      "Train on 21228 samples, validate on 1196 samples\n",
      "Epoch 1/30\n",
      "21228/21228 [==============================] - 1s - loss: 3.3251 - acc: 0.1922 - val_loss: 1.2465 - val_acc: 0.7232\n",
      "Epoch 2/30\n",
      "21228/21228 [==============================] - 1s - loss: 1.9261 - acc: 0.3778 - val_loss: 0.9934 - val_acc: 0.8361\n",
      "Epoch 3/30\n",
      "21228/21228 [==============================] - 1s - loss: 1.4667 - acc: 0.4978 - val_loss: 0.8867 - val_acc: 0.8077\n",
      "Epoch 4/30\n",
      "21228/21228 [==============================] - 1s - loss: 1.2475 - acc: 0.5705 - val_loss: 0.8220 - val_acc: 0.8278\n",
      "Epoch 5/30\n",
      "21228/21228 [==============================] - 1s - loss: 1.1458 - acc: 0.6058 - val_loss: 0.7920 - val_acc: 0.8311\n",
      "Epoch 6/30\n",
      "21228/21228 [==============================] - 1s - loss: 1.0711 - acc: 0.6326 - val_loss: 0.7516 - val_acc: 0.8520\n",
      "Epoch 7/30\n",
      "21228/21228 [==============================] - 1s - loss: 1.0323 - acc: 0.6472 - val_loss: 0.7577 - val_acc: 0.8353\n",
      "Epoch 8/30\n",
      "21228/21228 [==============================] - 1s - loss: 1.0056 - acc: 0.6551 - val_loss: 0.7707 - val_acc: 0.7968\n",
      "Epoch 9/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9817 - acc: 0.6679 - val_loss: 0.7310 - val_acc: 0.8328\n",
      "Epoch 10/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9676 - acc: 0.6736 - val_loss: 0.6899 - val_acc: 0.8562\n",
      "Epoch 11/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9498 - acc: 0.6745 - val_loss: 0.6710 - val_acc: 0.8386\n",
      "Epoch 12/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9399 - acc: 0.6837 - val_loss: 0.6976 - val_acc: 0.8227\n",
      "Epoch 13/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9350 - acc: 0.6820 - val_loss: 0.6671 - val_acc: 0.8512\n",
      "Epoch 14/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9334 - acc: 0.6823 - val_loss: 0.6477 - val_acc: 0.8278\n",
      "Epoch 15/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9062 - acc: 0.6959 - val_loss: 0.6672 - val_acc: 0.8269\n",
      "Epoch 16/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9193 - acc: 0.6899 - val_loss: 0.6479 - val_acc: 0.8370\n",
      "Epoch 17/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9002 - acc: 0.6939 - val_loss: 0.6670 - val_acc: 0.8386\n",
      "Epoch 18/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.9062 - acc: 0.6924 - val_loss: 0.6778 - val_acc: 0.8027\n",
      "Epoch 19/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8871 - acc: 0.6987 - val_loss: 0.6194 - val_acc: 0.8411\n",
      "Epoch 20/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8796 - acc: 0.7005 - val_loss: 0.6532 - val_acc: 0.8177\n",
      "Epoch 21/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8887 - acc: 0.6991 - val_loss: 0.6625 - val_acc: 0.8194\n",
      "Epoch 22/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8880 - acc: 0.6991 - val_loss: 0.6162 - val_acc: 0.8478\n",
      "Epoch 23/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8852 - acc: 0.7000 - val_loss: 0.6468 - val_acc: 0.8294\n",
      "Epoch 24/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8846 - acc: 0.6992 - val_loss: 0.6344 - val_acc: 0.8428\n",
      "Epoch 25/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8849 - acc: 0.6995 - val_loss: 0.6080 - val_acc: 0.8336\n",
      "Epoch 26/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8834 - acc: 0.6979 - val_loss: 0.6007 - val_acc: 0.8495\n",
      "Epoch 27/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8767 - acc: 0.7022 - val_loss: 0.6166 - val_acc: 0.8403\n",
      "Epoch 28/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8780 - acc: 0.7015 - val_loss: 0.6396 - val_acc: 0.8161\n",
      "Epoch 29/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8763 - acc: 0.7018 - val_loss: 0.6352 - val_acc: 0.8336\n",
      "Epoch 30/30\n",
      "21228/21228 [==============================] - 1s - loss: 0.8747 - acc: 0.7007 - val_loss: 0.6144 - val_acc: 0.8361\n"
     ]
    }
   ],
   "source": [
    "# 随机挑选一个司机出来作为验证集，保存bottleneck features，读取已经训练好的bottleneck features到模型中，\n",
    "# 读取后只训练全连接网络，重复8次，得到8个模型。\n",
    "nb_rounds = 8\n",
    "valid_driver_set = []\n",
    "target_size = (224,224)\n",
    "for i in range(nb_rounds):\n",
    "    print \"In \"+str(i+1)+\" round\"\n",
    "    np.random.shuffle(driver_char)\n",
    "    length = len(driver_char)\n",
    "    X_train, y_train, X_valid, y_valid = train_valid_split(resize=target_size,\n",
    "                                                           train_drivers=driver_char[:length-1],\n",
    "                                                           valid_drivers=driver_char[length-1:])\n",
    "    valid_driver_set.append(driver_char[length-1:])\n",
    "    path_1 = os.path.join('.', 'ResNet50_bottleneck_features_train_'+str(i)+'.npy')\n",
    "    path_2 = os.path.join('.', 'ResNet50_bottleneck_y_train_'+str(i)+'.npy')\n",
    "    path_3 = os.path.join('.', 'ResNet50_bottleneck_features_validation_'+str(i)+'.npy')\n",
    "    path_4 = os.path.join('.', 'ResNet50_bottleneck_y_valid_'+str(i)+'.npy')\n",
    "    if not (os.path.exists(path_1) and os.path.exists(path_2) and os.path.exists(path_3) and os.path.exists(path_4)):\n",
    "        print \"save bottleneck features...\"\n",
    "        save_bottlebeck_features(X_train, y_train, X_valid, y_valid, idx = i)\n",
    "    print \"Train fully connected layers...\"\n",
    "    train_data = np.load(open('ResNet50_bottleneck_features_train_'+str(i)+'.npy'))\n",
    "    train_label = np.load(open('ResNet50_bottleneck_y_train_'+str(i)+'.npy'))\n",
    "    validation_data = np.load(open('ResNet50_bottleneck_features_validation_'+str(i)+'.npy'))\n",
    "    validation_label = np.load(open('ResNet50_bottleneck_y_valid_'+str(i)+'.npy'))\n",
    "    print \"Train data shape: \"+str(train_data.shape)\n",
    "    print \"Train label shape:\"+str(train_label.shape)\n",
    "    print \"Valid data shape: \"+str(validation_data.shape)\n",
    "    print \"Valid label shape:\"+str(validation_label.shape)\n",
    "    \n",
    "    inputT = Input(train_data.shape[1:])\n",
    "    x = Dropout(0.8)(inputT) \n",
    "    x = Dense(10, activation='softmax', name='fc_10')(x)\n",
    "    model = Model(inputT, x)\n",
    "\n",
    "    model.compile(optimizer='adadelta',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_label,\n",
    "              epochs=30, batch_size=64, \n",
    "              shuffle=True, callbacks=[EarlyStopping(monitor='val_loss', min_delta=1e-4, patience=5)],\n",
    "              validation_data=(validation_data, validation_label))\n",
    "    model.save_weights('ResNet50_bottleneck_fc_model_'+str(i)+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['p022'], ['p066'], ['p022'], ['p021'], ['p039'], ['p012'], ['p042'], ['p002']]\n"
     ]
    }
   ],
   "source": [
    "# 随机选取的8个验证集司机，p022出现了两次\n",
    "print valid_driver_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 1 round, \n",
      "Remove p022 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p042', 'p024', 'p039', 'p066', 'p041', 'p072', 'p061', 'p012', 'p049', 'p064', 'p021', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p002']\n",
      "Validation drivers: ['p022']\n",
      "Train data shape:(21191, 224, 224, 3)\n",
      "Train label shape:(21191, 10)\n",
      "Validation data shape:(1233, 224, 224, 3)\n",
      "Validation label shape:(1233, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 694s - loss: 0.1643 - acc: 0.9597 - val_loss: 0.4466 - val_acc: 0.9023\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 692s - loss: 0.0364 - acc: 0.9924 - val_loss: 1.3184 - val_acc: 0.8897\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 691s - loss: 0.0154 - acc: 0.9965 - val_loss: 0.1361 - val_acc: 0.9696\n",
      "In 2 round, \n",
      "Remove p066 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p042', 'p024', 'p039', 'p041', 'p072', 'p061', 'p012', 'p049', 'p064', 'p021', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p002', 'p022']\n",
      "Validation drivers: ['p066']\n",
      "Train data shape:(21390, 224, 224, 3)\n",
      "Train label shape:(21390, 10)\n",
      "Validation data shape:(1034, 224, 224, 3)\n",
      "Validation label shape:(1034, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 696s - loss: 0.1325 - acc: 0.9644 - val_loss: 0.7203 - val_acc: 0.8241\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 693s - loss: 0.0226 - acc: 0.9947 - val_loss: 0.7648 - val_acc: 0.8329\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 693s - loss: 0.0089 - acc: 0.9980 - val_loss: 0.6005 - val_acc: 0.8577\n",
      "In 3 round, \n",
      "Remove p022 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p042', 'p024', 'p039', 'p041', 'p072', 'p061', 'p012', 'p049', 'p064', 'p021', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p002', 'p066']\n",
      "Validation drivers: ['p022']\n",
      "Train data shape:(21191, 224, 224, 3)\n",
      "Train label shape:(21191, 10)\n",
      "Validation data shape:(1233, 224, 224, 3)\n",
      "Validation label shape:(1233, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 696s - loss: 0.1388 - acc: 0.9652 - val_loss: 0.0890 - val_acc: 0.9736\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 695s - loss: 0.0216 - acc: 0.9949 - val_loss: 0.1852 - val_acc: 0.9711\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 696s - loss: 0.0092 - acc: 0.9980 - val_loss: 0.4605 - val_acc: 0.9186\n",
      "In 4 round, \n",
      "Remove p021 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p042', 'p024', 'p039', 'p041', 'p072', 'p061', 'p012', 'p049', 'p064', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p002', 'p066', 'p022']\n",
      "Validation drivers: ['p021']\n",
      "Train data shape:(21187, 224, 224, 3)\n",
      "Train label shape:(21187, 10)\n",
      "Validation data shape:(1237, 224, 224, 3)\n",
      "Validation label shape:(1237, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 701s - loss: 0.1504 - acc: 0.9617 - val_loss: 1.3081 - val_acc: 0.8627\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 697s - loss: 0.0300 - acc: 0.9928 - val_loss: 0.4517 - val_acc: 0.9196\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 698s - loss: 0.0103 - acc: 0.9974 - val_loss: 0.4731 - val_acc: 0.9243\n",
      "In 5 round, \n",
      "Remove p039 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p042', 'p024', 'p041', 'p072', 'p061', 'p012', 'p049', 'p064', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p002', 'p066', 'p022', 'p021']\n",
      "Validation drivers: ['p039']\n",
      "Train data shape:(21773, 224, 224, 3)\n",
      "Train label shape:(21773, 10)\n",
      "Validation data shape:(651, 224, 224, 3)\n",
      "Validation label shape:(651, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 702s - loss: 0.1395 - acc: 0.9631 - val_loss: 0.7815 - val_acc: 0.8159\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 697s - loss: 0.0272 - acc: 0.9939 - val_loss: 0.1926 - val_acc: 0.9290\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 696s - loss: 0.0095 - acc: 0.9977 - val_loss: 0.1781 - val_acc: 0.9525\n",
      "In 6 round, \n",
      "Remove p012 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p042', 'p024', 'p041', 'p072', 'p061', 'p049', 'p064', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p002', 'p066', 'p022', 'p021', 'p039']\n",
      "Validation drivers: ['p012']\n",
      "Train data shape:(21601, 224, 224, 3)\n",
      "Train label shape:(21601, 10)\n",
      "Validation data shape:(823, 224, 224, 3)\n",
      "Validation label shape:(823, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 701s - loss: 0.1610 - acc: 0.9587 - val_loss: 1.2080 - val_acc: 0.8648\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 697s - loss: 0.0344 - acc: 0.9923 - val_loss: 0.8345 - val_acc: 0.8694\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 697s - loss: 0.0115 - acc: 0.9963 - val_loss: 0.7672 - val_acc: 0.8521\n",
      "In 7 round, \n",
      "Remove p042 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p024', 'p041', 'p072', 'p061', 'p049', 'p064', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p002', 'p066', 'p022', 'p021', 'p039', 'p012']\n",
      "Validation drivers: ['p042']\n",
      "Train data shape:(21833, 224, 224, 3)\n",
      "Train label shape:(21833, 10)\n",
      "Validation data shape:(591, 224, 224, 3)\n",
      "Validation label shape:(591, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 704s - loss: 0.1606 - acc: 0.9595 - val_loss: 0.0396 - val_acc: 0.9900\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 698s - loss: 0.0226 - acc: 0.9943 - val_loss: 0.2575 - val_acc: 0.9232\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 697s - loss: 0.0124 - acc: 0.9970 - val_loss: 0.8963 - val_acc: 0.8969\n",
      "In 8 round, \n",
      "Remove p002 from driver set...\n",
      "Train drivers: ['p015', 'p075', 'p016', 'p024', 'p041', 'p072', 'p061', 'p049', 'p064', 'p056', 'p045', 'p052', 'p050', 'p081', 'p026', 'p014', 'p035', 'p051', 'p047', 'p066', 'p022', 'p021', 'p039', 'p012', 'p042']\n",
      "Validation drivers: ['p002']\n",
      "Train data shape:(21699, 224, 224, 3)\n",
      "Train label shape:(21699, 10)\n",
      "Validation data shape:(725, 224, 224, 3)\n",
      "Validation label shape:(725, 10)\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 703s - loss: 0.1577 - acc: 0.9600 - val_loss: 0.5442 - val_acc: 0.9079\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 698s - loss: 0.0308 - acc: 0.9931 - val_loss: 0.3210 - val_acc: 0.9218\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 698s - loss: 0.0074 - acc: 0.9979 - val_loss: 0.6362 - val_acc: 0.9151\n"
     ]
    }
   ],
   "source": [
    "# 针对每个模型进行fine-tune\n",
    "# 训练完成后保存模型参数和模型结构\n",
    "# 注意： 第一个p022完成后要将名字改为p022_01，否则会被覆盖。\n",
    "n = 8\n",
    "batch_size = 16\n",
    "for i in range(n):\n",
    "    print \"In \"+str(i+1)+\" round, \"\n",
    "    model = ResNet50(include_top=False, weights='imagenet', pooling='max')\n",
    "    x = Dropout(.8)(model.output) \n",
    "    x = Dense(10, activation='softmax', name='fc_10')(x)\n",
    "    ResNet50_model = Model(model.input, x)\n",
    "    ResNet50_model.load_weights('ResNet50_bottleneck_fc_model_'+str(i)+'.h5', by_name=True)\n",
    "    for layer in ResNet50_model.layers[:100]:\n",
    "        layer.trainable = False\n",
    "    for layer in ResNet50_model.layers[100:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    X_train =[]\n",
    "    y_train =[]\n",
    "    X_valid =[]\n",
    "    y_valid =[]\n",
    "    \n",
    "    print \"Remove \"+str(valid_driver_set[i][0])+\" from driver set...\"\n",
    "    driver_char.remove(valid_driver_set[i][0])\n",
    "    X_train, y_train, X_valid, y_valid = train_valid_split(resize=(224,224),\n",
    "                                                           train_drivers=driver_char, \n",
    "                                                           valid_drivers=valid_driver_set[i])\n",
    "    driver_char.append(valid_driver_set[i][0])\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "    validation_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "    \n",
    "    train_generator = train_datagen.flow(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "    validation_generator = validation_datagen.flow(\n",
    "        X_valid, y_valid,\n",
    "        batch_size=batch_size,\n",
    "            shuffle=True)\n",
    "    ResNet50_model.compile(optimizer=Adadelta(),\n",
    "                      loss='categorical_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "    ResNet50_model.fit_generator(train_generator,\n",
    "                        steps_per_epoch=2000,\n",
    "                        validation_data=validation_generator,\n",
    "                        validation_steps=150,\n",
    "                        epochs=3,\n",
    "                        verbose=1)\n",
    "    # Save the transfer learning results and model\n",
    "    ResNet50_model.save_weights('ResNet50_model_'+str(i)+'.h5')\n",
    "    with open('ResNet50_model_'+str(i)+'.json', 'w') as f:\n",
    "        f.write(ResNet50_model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# 读取一张照片，进行一次预测。\n",
    "# Try to predict\n",
    "def load_and_predict_dataset(model):\n",
    "    count = 0\n",
    "    pred = dict()\n",
    "    path = os.path.join('.', 'imgs', 'test', '*.jpg')\n",
    "    files = glob.glob(path) # lazy matched file names\n",
    "    for f in files:\n",
    "        basename = os.path.basename(f)\n",
    "        prefix = basename.split('.')[0]\n",
    "        main = prefix.split('_')[1]\n",
    "        img = cv2.imread(f)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        img = np.array(img, dtype=float)\n",
    "        img = preprocess_input(img)\n",
    "        img = np.reshape(img, (1,224,224,3))\n",
    "        pred_prob = model.predict(img)\n",
    "        pred_prob = pred_prob.clip(min=0.005, max=0.995)\n",
    "        if main not in pred.keys():\n",
    "            pred[main] = [] # init a list\n",
    "        pred[main].append(pred_prob)\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print \"Load and predict \"+str(count)+\" imgs \"\n",
    "#             break\n",
    "    print \"Load and predict \"+str(count)+\" imgs \"\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重新得到验证司机集\n",
    "valid_driver_set = [['p022_01'], ['p066'], ['p022'], ['p021'], ['p039'], ['p012'], ['p042'], ['p002']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load model from ResNet50_model_0.json\n",
      "Load weights from ResNet50_model_0.h5\n",
      "Load and predict 1000 imgs \n",
      "Load and predict 2000 imgs \n",
      "Load and predict 3000 imgs \n",
      "Load and predict 4000 imgs \n",
      "Load and predict 5000 imgs \n",
      "Load and predict 6000 imgs \n",
      "Load and predict 7000 imgs \n",
      "Load and predict 8000 imgs \n",
      "Load and predict 9000 imgs \n",
      "Load and predict 10000 imgs \n",
      "Load and predict 11000 imgs \n",
      "Load and predict 12000 imgs \n",
      "Load and predict 13000 imgs \n",
      "Load and predict 14000 imgs \n",
      "Load and predict 15000 imgs \n",
      "Load and predict 16000 imgs \n",
      "Load and predict 17000 imgs \n",
      "Load and predict 18000 imgs \n",
      "Load and predict 19000 imgs \n",
      "Load and predict 20000 imgs \n",
      "Load and predict 21000 imgs \n",
      "Load and predict 22000 imgs \n",
      "Load and predict 23000 imgs \n",
      "Load and predict 24000 imgs \n",
      "Load and predict 25000 imgs \n",
      "Load and predict 26000 imgs \n",
      "Load and predict 27000 imgs \n",
      "Load and predict 28000 imgs \n",
      "Load and predict 29000 imgs \n",
      "Load and predict 30000 imgs \n",
      "Load and predict 31000 imgs \n",
      "Load and predict 32000 imgs \n",
      "Load and predict 33000 imgs \n",
      "Load and predict 34000 imgs \n",
      "Load and predict 35000 imgs \n",
      "Load and predict 36000 imgs \n",
      "Load and predict 37000 imgs \n",
      "Load and predict 38000 imgs \n",
      "Load and predict 39000 imgs \n",
      "Load and predict 40000 imgs \n",
      "Load and predict 41000 imgs \n",
      "Load and predict 42000 imgs \n",
      "Load and predict 43000 imgs \n",
      "Load and predict 44000 imgs \n",
      "Load and predict 45000 imgs \n",
      "Load and predict 46000 imgs \n",
      "Load and predict 47000 imgs \n",
      "Load and predict 48000 imgs \n",
      "Load and predict 49000 imgs \n",
      "Load and predict 50000 imgs \n",
      "Load and predict 51000 imgs \n",
      "Load and predict 52000 imgs \n",
      "Load and predict 53000 imgs \n",
      "Load and predict 54000 imgs \n",
      "Load and predict 55000 imgs \n",
      "Load and predict 56000 imgs \n",
      "Load and predict 57000 imgs \n",
      "Load and predict 58000 imgs \n",
      "Load and predict 59000 imgs \n",
      "Load and predict 60000 imgs \n",
      "Load and predict 61000 imgs \n",
      "Load and predict 62000 imgs \n",
      "Load and predict 63000 imgs \n",
      "Load and predict 64000 imgs \n",
      "Load and predict 65000 imgs \n",
      "Load and predict 66000 imgs \n",
      "Load and predict 67000 imgs \n",
      "Load and predict 68000 imgs \n",
      "Load and predict 69000 imgs \n",
      "Load and predict 70000 imgs \n",
      "Load and predict 71000 imgs \n",
      "Load and predict 72000 imgs \n",
      "Load and predict 73000 imgs \n",
      "Load and predict 74000 imgs \n",
      "Load and predict 75000 imgs \n",
      "Load and predict 76000 imgs \n",
      "Load and predict 77000 imgs \n",
      "Load and predict 78000 imgs \n",
      "Load and predict 79000 imgs \n",
      "Load and predict 79726 imgs \n",
      "write 79726 lines!\n",
      "Load model from ResNet50_model_1.json\n",
      "Load weights from ResNet50_model_1.h5\n",
      "Load and predict 1000 imgs \n",
      "Load and predict 2000 imgs \n",
      "Load and predict 3000 imgs \n",
      "Load and predict 4000 imgs \n",
      "Load and predict 5000 imgs \n",
      "Load and predict 6000 imgs \n",
      "Load and predict 7000 imgs \n",
      "Load and predict 8000 imgs \n",
      "Load and predict 9000 imgs \n",
      "Load and predict 10000 imgs \n",
      "Load and predict 11000 imgs \n",
      "Load and predict 12000 imgs \n",
      "Load and predict 13000 imgs \n",
      "Load and predict 14000 imgs \n",
      "Load and predict 15000 imgs \n",
      "Load and predict 16000 imgs \n",
      "Load and predict 17000 imgs \n",
      "Load and predict 18000 imgs \n",
      "Load and predict 19000 imgs \n",
      "Load and predict 20000 imgs \n",
      "Load and predict 21000 imgs \n",
      "Load and predict 22000 imgs \n",
      "Load and predict 23000 imgs \n",
      "Load and predict 24000 imgs \n",
      "Load and predict 25000 imgs \n",
      "Load and predict 26000 imgs \n",
      "Load and predict 27000 imgs \n",
      "Load and predict 28000 imgs \n",
      "Load and predict 29000 imgs \n",
      "Load and predict 30000 imgs \n",
      "Load and predict 31000 imgs \n",
      "Load and predict 32000 imgs \n",
      "Load and predict 33000 imgs \n",
      "Load and predict 34000 imgs \n",
      "Load and predict 35000 imgs \n",
      "Load and predict 36000 imgs \n",
      "Load and predict 37000 imgs \n",
      "Load and predict 38000 imgs \n",
      "Load and predict 39000 imgs \n",
      "Load and predict 40000 imgs \n",
      "Load and predict 41000 imgs \n",
      "Load and predict 42000 imgs \n",
      "Load and predict 43000 imgs \n",
      "Load and predict 44000 imgs \n",
      "Load and predict 45000 imgs \n",
      "Load and predict 46000 imgs \n",
      "Load and predict 47000 imgs \n",
      "Load and predict 48000 imgs \n",
      "Load and predict 49000 imgs \n",
      "Load and predict 50000 imgs \n",
      "Load and predict 51000 imgs \n",
      "Load and predict 52000 imgs \n",
      "Load and predict 53000 imgs \n",
      "Load and predict 54000 imgs \n",
      "Load and predict 55000 imgs \n",
      "Load and predict 56000 imgs \n",
      "Load and predict 57000 imgs \n",
      "Load and predict 58000 imgs \n",
      "Load and predict 59000 imgs \n",
      "Load and predict 60000 imgs \n",
      "Load and predict 61000 imgs \n",
      "Load and predict 62000 imgs \n",
      "Load and predict 63000 imgs \n",
      "Load and predict 64000 imgs \n",
      "Load and predict 65000 imgs \n",
      "Load and predict 66000 imgs \n",
      "Load and predict 67000 imgs \n",
      "Load and predict 68000 imgs \n",
      "Load and predict 69000 imgs \n",
      "Load and predict 70000 imgs \n",
      "Load and predict 71000 imgs \n",
      "Load and predict 72000 imgs \n",
      "Load and predict 73000 imgs \n",
      "Load and predict 74000 imgs \n",
      "Load and predict 75000 imgs \n",
      "Load and predict 76000 imgs \n",
      "Load and predict 77000 imgs \n",
      "Load and predict 78000 imgs \n",
      "Load and predict 79000 imgs \n",
      "Load and predict 79726 imgs \n",
      "write 79726 lines!\n",
      "Load model from ResNet50_model_2.json\n",
      "Load weights from ResNet50_model_2.h5\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99e4116c72ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Load model from ResNet50_model_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Load weights from ResNet50_model_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mResNet50_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResNet50_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mResNet50_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResNet50_model_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_predict_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet50_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 读取模型和模型参数，对测试集进行预测\n",
    "for i in range(8):\n",
    "    print \"Load model from ResNet50_model_\"+str(i)+\".json\"\n",
    "    print \"Load weights from ResNet50_model_\"+str(i)+\".h5\"\n",
    "    ResNet50_model = model_from_json(open('ResNet50_model_'+str(index[i])+'.json').read())  \n",
    "    ResNet50_model.load_weights('ResNet50_model_'+str(index[i])+'.h5') \n",
    "    pred = load_and_predict_dataset(ResNet50_model)\n",
    "    count = 0\n",
    "    head = \"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\"\n",
    "    with open('predict_'+valid_driver_set[i][0]+'.csv', 'w') as f:\n",
    "        f.write(head)\n",
    "        for item in pred.keys():\n",
    "            prob = pred[item][0][0]\n",
    "            count += 1\n",
    "            line = \"img_\"+item+'.jpg,'+str(prob[0])+',' \\\n",
    "                                      +str(prob[1])+',' \\\n",
    "                                    +str(prob[2])+',' \\\n",
    "                                    +str(prob[3])+',' \\\n",
    "                                    +str(prob[4])+',' \\\n",
    "                                    +str(prob[5])+',' \\\n",
    "                                    +str(prob[6])+',' \\\n",
    "                                    +str(prob[7])+',' \\\n",
    "                                    +str(prob[8])+',' \\\n",
    "                                    +str(prob[9])+'\\n'\n",
    "            f.write(line)\n",
    "    #     if count == 5:\n",
    "    #         break\n",
    "    print \"write \"+str(count)+\" lines!\"\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "write 79726 lines!\n"
     ]
    }
   ],
   "source": [
    "# 选取较好的5个模型，将预测值求平均。\n",
    "prediction_fname = ['p042', 'p002', 'p022_01', 'p039', 'p021']\n",
    "goal = np.zeros((79726, 10))\n",
    "for fname in prediction_fname:\n",
    "    path = os.path.join('.', 'predict_'+fname+'.csv')\n",
    "    p = pd.read_csv(path)\n",
    "    goal += p.drop('img', axis=1)\n",
    "goal = goal / 5\n",
    "img_name = p['img']\n",
    "count = 0\n",
    "head = \"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\"\n",
    "with open('predict_avg.csv', 'w') as f:\n",
    "    f.write(head)\n",
    "    for i, prob in enumerate(goal):\n",
    "        count += 1\n",
    "        line = img_name[i]+','+str(prob[0])+',' \\\n",
    "                                  +str(prob[1])+',' \\\n",
    "                                +str(prob[2])+',' \\\n",
    "                                +str(prob[3])+',' \\\n",
    "                                +str(prob[4])+',' \\\n",
    "                                +str(prob[5])+',' \\\n",
    "                                +str(prob[6])+',' \\\n",
    "                                +str(prob[7])+',' \\\n",
    "                                +str(prob[8])+',' \\\n",
    "                                +str(prob[9])+'\\n'\n",
    "        f.write(line)\n",
    "#     if count == 5:\n",
    "#         break\n",
    "print \"write \"+str(count)+\" lines!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculate conv output of model 0...\n"
     ]
    }
   ],
   "source": [
    "# 针对每个模型，获取每张测试图片在卷积层的输出和图片名称，分别保存成npy格式\n",
    "# Get indices of the 10 nearest neighbors of each test image.\n",
    "# Store the convolutional outputs of each test image.\n",
    "for k in range(8):\n",
    "    print \"Calculate conv output of model \"+str(k)+'...'\n",
    "    model = model_from_json(open('resnet50_models/ResNet50_model_'+str(k)+'.json').read())  \n",
    "    model.load_weights('resnet50_models/ResNet50_model_'+str(k)+'.h5')\n",
    "    model_conv = Model(model.input, model.layers[172].output)\n",
    "    path = os.path.join('.', 'imgs', 'test', '*.jpg')\n",
    "    img_names = glob.glob(path)\n",
    "    conv_weights = []\n",
    "    name_list = []\n",
    "    count = 0\n",
    "    for i, img_path in enumerate(img_names):\n",
    "        count += 1\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        conv_outputs = model_conv.predict(np.expand_dims(img, axis=0))\n",
    "        # 为了防止计算时间过长，将(7,7,2048)取前两个维度的均值，(7,7,2048)->(2048)\n",
    "        conv_space_mean = [np.mean(conv_outputs[0][:,:,d]) for d in range(2048)]\n",
    "        conv_weights.append(conv_space_mean)\n",
    "        name_list.append(os.path.basename(img_path))\n",
    "        if count % 10000 == 0:\n",
    "            print \"Predict \"+str(count)+\" imgs \"\n",
    "    print \"Predict \"+str(count)+\" imgs, exit! \"\n",
    "    np.save(open('model_'+str(k)+'_knn_weights.npy', 'w'),\n",
    "                np.array(conv_weights))\n",
    "    np.save(open('model_'+str(k)+'_name_list.npy', 'w'),\n",
    "                np.array(name_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating neighbors of model 0...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 0th 10 neighbors DONE, EXIT!\n",
      "Calculating neighbors of model 1...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 1th 10 neighbors DONE, EXIT!\n",
      "Calculating neighbors of model 2...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 2th 10 neighbors DONE, EXIT!\n",
      "Calculating neighbors of model 3...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 3th 10 neighbors DONE, EXIT!\n",
      "Calculating neighbors of model 4...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 4th 10 neighbors DONE, EXIT!\n",
      "Calculating neighbors of model 5...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 5th 10 neighbors DONE, EXIT!\n",
      "Calculating neighbors of model 6...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 6th 10 neighbors DONE, EXIT!\n",
      "Calculating neighbors of model 7...\n",
      "write 0's neighbors.\n",
      "write 10000's neighbors.\n",
      "write 20000's neighbors.\n",
      "write 30000's neighbors.\n",
      "write 40000's neighbors.\n",
      "write 50000's neighbors.\n",
      "write 60000's neighbors.\n",
      "write 70000's neighbors.\n",
      "Calculate 7th 10 neighbors DONE, EXIT!\n"
     ]
    }
   ],
   "source": [
    "# 使用sklearn中的KNN API，特征为卷积层的输出，计算测试集中每一张图片的10个近邻，保存到csv文件中\n",
    "for k in range(8):\n",
    "    print \"Calculating neighbors of model \"+str(k)+'...'\n",
    "    conv_weights = np.load(open('model_'+str(k)+'_knn_weights.npy'))\n",
    "    name_list = np.load(open('model_'+str(k)+'_name_list.npy'))\n",
    "    neigh = NearestNeighbors(n_neighbors=11)\n",
    "    neigh.fit(conv_weights)\n",
    "    neighbors = neigh.kneighbors(conv_weights, return_distance=False)\n",
    "    # Calculate 10 nearest neighbors... Store the basenames\n",
    "    head = \"img,1,2,3,4,5,6,7,8,9,10\\n\"\n",
    "    with open('model_'+str(k)+'_knn.csv', 'w') as f:\n",
    "        f.write(head)\n",
    "        for i, n in enumerate(neighbors):\n",
    "            knn_index = n[1:]\n",
    "            line = name_list[i]+','+str(name_list[knn_index[0]])+',' \\\n",
    "                                      +str(name_list[knn_index[1]])+',' \\\n",
    "                                    +str(name_list[knn_index[2]])+',' \\\n",
    "                                    +str(name_list[knn_index[3]])+',' \\\n",
    "                                    +str(name_list[knn_index[4]])+',' \\\n",
    "                                    +str(name_list[knn_index[5]])+',' \\\n",
    "                                    +str(name_list[knn_index[6]])+',' \\\n",
    "                                    +str(name_list[knn_index[7]])+',' \\\n",
    "                                    +str(name_list[knn_index[8]])+',' \\\n",
    "                                    +str(name_list[knn_index[9]])+'\\n'\n",
    "            f.write(line)\n",
    "            if i % 10000 == 0:\n",
    "                print \"write \"+str(i)+\"'s neighbors.\"\n",
    "        print \"Calculate \"+str(k)+\"th 10 neighbors DONE, EXIT!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在已经得到结果中搜索指定图片的预测概率值\n",
    "def searchDataFrame(src_data, tar_data, img_fname):\n",
    "    '''\n",
    "    src_data: knn table\n",
    "    tar_data: prob table\n",
    "    Search probs of the img from src_data\n",
    "    return: (10,) prob of that img\n",
    "    '''\n",
    "    ret = 0\n",
    "    neighbors = src_data.loc[src_data['img']==img_fname]\n",
    "    neighbors = np.array(neighbors)\n",
    "    for i, nei in enumerate(neighbors[0]):\n",
    "        ret += 1./11 * np.array(tar_data.loc[tar_data['img']==nei])[0][1:]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 计算测试集中每张照片和其10个近邻的平均概率值\n",
    "model_name = ['p022_01', 'p066', 'p022', 'p021', 'p039', 'p012', 'p042', 'p002']\n",
    "for i in range(8):\n",
    "    pred = pd.read_csv('predict_'+str(model_name[i])+'.csv')\n",
    "    knn = pd.read_csv('resnet50_models/model_'+str(i)+'_knn.csv')\n",
    "    print \"Read knn from model \"+model_name[i]+\"...\"\n",
    "    count = 0\n",
    "    name_list = np.array(pred['img'])\n",
    "    head = \"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\"\n",
    "    with open('predict_'+str(model_name[i])+'_KNN.csv', 'w') as f:\n",
    "        f.write(head)\n",
    "        print 'Calculate knn prediction...'\n",
    "        for name in name_list:\n",
    "            prob = searchDataFrame(knn, pred, name)\n",
    "            count += 1\n",
    "            line = name+','+str(prob[0])+',' \\\n",
    "                                      +str(prob[1])+',' \\\n",
    "                                    +str(prob[2])+',' \\\n",
    "                                    +str(prob[3])+',' \\\n",
    "                                    +str(prob[4])+',' \\\n",
    "                                    +str(prob[5])+',' \\\n",
    "                                    +str(prob[6])+',' \\\n",
    "                                    +str(prob[7])+',' \\\n",
    "                                    +str(prob[8])+',' \\\n",
    "                                    +str(prob[9])+'\\n'\n",
    "            f.write(line)\n",
    "            if count % 10000 == 0:\n",
    "                print \"Predict \"+str(count)+\" imgs \"\n",
    "    print \"write \"+str(count)+\" lines! DONE!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 选出6个表现较好的模型，对他们的预测概率再做一次平均。\n",
    "pick_model = ['p039', 'p042', 'p021', 'p066', 'p022_01','p002']\n",
    "head = \"img,c0,c1,c2,c3,c4,c5,c6,c7,c8,c9\\n\"\n",
    "data = np.zeros((79726, 10))\n",
    "with open('predict_6_model_avg.csv', 'w') as f:\n",
    "    f.write(head)\n",
    "    for i in range(6):\n",
    "        pick = pd.read_csv('predict_'+str(pick_model[i])+'_KNN.csv')\n",
    "        name_list = np.array(pick['img'])\n",
    "        data += np.array(pick.drop('img', axis=1))\n",
    "        print \"Read predict from model \"+pick_model[i]+\"...\"\n",
    "    data = data / 6.\n",
    "    print 'Calculate knn prediction...'\n",
    "    for i, name in enumerate(name_list):\n",
    "        line = name+','+str(data[i][0])+',' \\\n",
    "                                  +str(data[i][1])+',' \\\n",
    "                                +str(data[i][2])+',' \\\n",
    "                                +str(data[i][3])+',' \\\n",
    "                                +str(data[i][4])+',' \\\n",
    "                                +str(data[i][5])+',' \\\n",
    "                                +str(data[i,6])+',' \\\n",
    "                                +str(data[i][7])+',' \\\n",
    "                                +str(data[i][8])+',' \\\n",
    "                                +str(data[i][9])+'\\n'\n",
    "        f.write(line)\n",
    "    print \"DONE!\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
